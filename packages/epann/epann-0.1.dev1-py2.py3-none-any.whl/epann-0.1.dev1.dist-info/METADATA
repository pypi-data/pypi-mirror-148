Metadata-Version: 2.1
Name: epann
Version: 0.1.dev1
Summary: EPANN: Evolving Plastic Artificial Networks for General Intelligence
Home-page: https://github.com/WorldEditors/EvolvingPRNN
Author: World_Editors
Author-email: 
License: GPLv3
Platform: UNKNOWN
Description-Content-Type: text/markdown
Requires-Dist: gym (>=0.18.0)
Requires-Dist: numpy (>=1.16.4)
Requires-Dist: Pillow (>=6.2.2)
Requires-Dist: six (>=1.12.0)
Requires-Dist: metagym (>0.1.0)
Requires-Dist: parl (>=1.4.1)

# Introduction
A crucial difference between artificial neural networks (ANNs) and biological neural networks (BNNs) is that BNNs can acquire new skills across variant tasks on their own. Motivated by BNNs, we try to implement the "Learning By Interaction" principle in the meta-learning framework. We aim to unify supervised learning, reinforcement learning, and unsupervised learning in a model-based / plasticity-based manner. The learning no longer relies on human-designed target function and optimization but through the black-box mechanism of the neural networks and plasticity rules. We build this evolving plasticity repo to facilitate the research on this topic.

# Requirement
python >= 3.7.4

parl == 1.4.1

numpy >= 1.8.1

metagym >= 0.1.0

# Run Meta-Training in Random Maze-2D environments
```bash
python run_train.py config_maze_train
```

# Run Meta-Testing in Random Maze-2D environments
```bash
python run_test.py config_maze_test
```

If you are to use parallelization mode, start xparl master on your remote server by using: 
```bash
xparl start --cpu_num $cpu_num --port $port_id
```
and change the "server" configuration to "$IP_ADDRESS:$port_id".
Also be sure that "$cpu_num" surpass the "actor_number" in the configuration file


